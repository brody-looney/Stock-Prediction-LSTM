{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FB-LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfmXyyOjvAL8U4ZDJNrT3r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brody-looney/Stock-Prediction-LSTM/blob/main/FB_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86QWC3THwDJp"
      },
      "source": [
        "#Author: Brody Looney\n",
        "#File: FB-LSTM.ipynb\n",
        "#Purpose: Stock Predictor LSTM for COS470 Project. This model trains and tests on FB data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrTPp3zaoIs9"
      },
      "source": [
        "#upload FB_train.csv and FB_test.csv files here\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ff7h5kcwoMRy"
      },
      "source": [
        "#Importing the necessary attributes\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "\n",
        "#Importing pre-split train and test sets (80/20)\n",
        "train = pd.read_csv('FB_train.csv')\n",
        "test = pd.read_csv('FB_test.csv')\n",
        "\n",
        "#Dates to be used in the graph\n",
        "dates = list(test['Date'])\n",
        "dates = [dt.datetime.strptime(date, '%m/%d/%Y').date() for date in dates]\n",
        "\n",
        "#Dropping the columns that won't be used in this type of predictor. This model only uses\n",
        "#EMAs and the close price\n",
        "train = train.drop(['Date', 'Volume', 'Open', 'High', 'Low'], axis = 1)\n",
        "\n",
        "#Creating a scaler which will be used to scale down the train data\n",
        "train_scaler = MinMaxScaler()\n",
        "\n",
        "scaled_train = train_scaler.fit_transform(train)\n",
        "\n",
        "#Splitting the data up into X and y sets that will be in the necessary shape for the LSTM\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(1, train.shape[0]):\n",
        "    X_train.append(scaled_train[i-1:i])\n",
        "    y_train.append(scaled_train[i, 0])\n",
        "    \n",
        "X_train, y_train = np.array(X_train), np.array(y_train)\n",
        "\n",
        "#Creating the LSTM model with multiple layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 4)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(units = 50, return_sequences = True))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(units = 60, return_sequences = True))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(LSTM(units = 80))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(units = 1))\n",
        "\n",
        "#LSTM Compilation\n",
        "model.compile(optimizer='adam', loss = 'mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=10)\n",
        "\n",
        "#Creating a scaler for the test set\n",
        "test_scaler = MinMaxScaler()\n",
        "scaled_test = test.drop(['Date', 'Volume', 'Open', 'High', 'Low'], axis = 1)\n",
        "scaled_test = test_scaler.fit_transform(scaled_test)\n",
        "\n",
        "#Creating x and y test sets\n",
        "X_test = []\n",
        "y_test = []\n",
        "dates_pred = []\n",
        "\n",
        "for i in range(1, scaled_test.shape[0]):\n",
        "    X_test.append(scaled_test[i-1:i])\n",
        "    y_test.append(scaled_test[i, 0])\n",
        "    dates_pred.append(dates[i])\n",
        "\n",
        "X_test, y_test = np.array(X_test), np.array(y_test)\n",
        "\n",
        "#Creating a value of the inverse of the scale so that it can be used to readjust the real price and prediction.\n",
        "scale = 1/0.00816793\n",
        "\n",
        "#Creating a prediction on the test data and scaling it \n",
        "prediction = model.predict(X_test)\n",
        "prediction = prediction * scale + 145\n",
        "\n",
        "#Getting the real price from the test set to compare the prediction to\n",
        "real = test.drop(['Date', 'Volume', 'EMA10', 'EMA50', 'EMA200', 'Open', 'High', 'Low'], axis = 1)\n",
        "\n",
        "#Printing the Real Price of FB using real\n",
        "plt.figure(figsize=(14,5))\n",
        "plt.plot(dates, real, color = 'red', label = 'Real FB Stock Price')\n",
        "plt.gcf().autofmt_xdate()\n",
        "plt.title('FB Stock Price')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('FB Stock Price')\n",
        "\n",
        "#Printing the prediction of the price of AAPL by using values of prediction\n",
        "plt.plot(dates_pred, prediction, color = 'blue', label = 'Predicted FB Stock Price')\n",
        "plt.gcf().autofmt_xdate()\n",
        "plt.title('FB Stock Price Prediction')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('FB Stock Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sN92oxesrDO-",
        "outputId": "51ee7f6b-9400-4b93-9092-b5476ad94fd2"
      },
      "source": [
        "train_scaler.scale_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00607497, 0.00607497, 0.00607497, 0.00592277])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTQEVkyEriS5",
        "outputId": "c6deb2e3-72bc-4228-ce07-5cb4f0d35149"
      },
      "source": [
        "test_scaler.scale_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00918695, 0.00918695, 0.00918695, 0.00816793])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    }
  ]
}
